{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"colab":{"name":"retrieval_1_40X.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"edOP5NGGzacJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513110783,"user_tz":-420,"elapsed":4979,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"0835daf9-f774-4080-e961-2148f336ca0e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9U656J6fzgPP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513118420,"user_tz":-420,"elapsed":2571,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"e8b0299d-a773-4f71-c40a-c3c10e9a8b14"},"source":["%cd '/content/drive/MyDrive/Image Retrieval'\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Image Retrieval\n"," augmentation.ipynb\n"," binary_scenario\n"," binary_scenario_augmented_400X\n"," checkpoint\n"," citra_split.ipynb\n"," comparing_graph.ipynb\n"," comparing_retrieval.ipynb\n"," core\n","'data binary splitting.ipynb'\n","'data subclass splitting.ipynb'\n"," extract_feature_binary.ipynb\n"," extract_feature_subclass.ipynb\n"," original\n"," paper\n"," reconstruction\n"," retrieval_1_100X.ipynb\n"," retrieval_1_100X_subclass.ipynb\n"," retrieval_1_200X.ipynb\n"," retrieval_1_200X_subclass.ipynb\n"," retrieval_1_400X.ipynb\n"," retrieval_1_400X_subclass.ipynb\n"," retrieval_1_40X.ipynb\n"," retrieval_1_40X_subclass.ipynb\n"," subclass_400\n"," subclass_scenario\n"," train_auto_encoder_magnification_1_100.ipynb\n"," train_auto_encoder_magnification_1_200.ipynb\n"," train_auto_encoder_magnification_1_400.ipynb\n"," train_auto_encoder_magnification_1_40.ipynb\n"," train_auto_encoder_subclass_1_100.ipynb\n"," train_auto_encoder_subclass_1_200.ipynb\n"," train_auto_encoder_subclass_1_400.ipynb\n"," train_auto_encoder_subclass_1_40.ipynb\n"," training_1_100\n"," training_1_100.h5\n"," training_1_100.json\n"," training_1_100_subclass\n"," training_1_100_subclass.h5\n"," training_1_100_subclass.json\n"," training_1_200\n"," training_1_200.h5\n"," training_1_200.json\n"," training_1_200_subclass\n"," training_1_200_subclass.h5\n"," training_1_200_subclass.json\n"," training_1_40\n"," training_1_400\n"," training_1_400.json\n"," training_1_400_subclass\n"," training_1_400_subclass.h5\n"," training_1_400_subclass.json\n"," training_1_40.h5\n"," training_1_40.json\n"," training_1_40_subclass\n"," training_1_40_subclass.h5\n"," training_1_40_subclass.json\n"," training_1.h5\n"," training_1_indexed_100.json\n"," training_1_indexed_100_subclass.json\n"," training_1_indexed_200.json\n"," training_1_indexed_200_subclass.json\n"," training_1_indexed_400.json\n"," training_1_indexed_400_subclass.json\n"," training_1_indexed_40.json\n"," training_1_indexed_40_subclass.json\n"," training_1.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qeU0dURVzFQ_"},"source":["import copy\n","import numpy as np\n","import os\n","import json\n","import cv2\n","import sklearn.metrics as metric\n","from core.AutoEncoder1 import ConvAutoEncoder\n","from tensorflow.keras.models import Model\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"ZEM6gOo_zFRA"},"source":["def euclidean(a, b):\n","\t# compute and return the euclidean distance between two vectors\n","\treturn np.linalg.norm(a - b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"LR197Y-TzFRA"},"source":["def perform_search(query_features, indexed_train, max_results=5):\n","\tretrieved = []\n","\tfor idx in range(0, len(indexed_train[\"features\"])):\n","\t\tdistance = euclidean(query_features, indexed_train[\"features\"][idx])\n","\t\tretrieved.append((distance, idx))\n","\tretrieved = sorted(retrieved)[:max_results]\n","\treturn retrieved"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"gYF06v7szFRA"},"source":["base_dataset = \"binary_scenario\"\n","magnification = \"40X\"\n","class_dir = ['benign', 'malignant']\n","IMAGE_SIZE = (256, 256)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"8-4mOToJzFRA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513121117,"user_tz":-420,"elapsed":3211,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"4502b9e8-3191-4da2-b8ca-5631620075ff"},"source":["print(\"[INFO] indexing file images BreaKHis dataset...\")\n","# indexing file images\n","dataset = []\n","for class_item in class_dir:\n","    cur_dir = os.path.join(base_dataset, 'test', magnification, class_item)\n","    for file in os.listdir(cur_dir):\n","        dataset.append(os.path.join(cur_dir, file))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] indexing file images BreaKHis dataset...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"aMiMBbTIzFRC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513126797,"user_tz":-420,"elapsed":1577,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"1a341708-1754-481a-990a-aaeb715a1f41"},"source":["print(\"len to retrieving:\", len(dataset))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["len to retrieving: 199\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"MN4HvCzkzFRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513134536,"user_tz":-420,"elapsed":4477,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"487ec64b-7185-43f4-cc10-f4b314da6f16"},"source":["print(\"[INFO] load images BreaKHis dataset...\")\n","#  load images\n","images = []\n","for image_path in dataset:\n","    if \".png\" in image_path:\n","        image = cv2.imread(image_path)\n","        image = cv2.resize(image, IMAGE_SIZE)\n","        images.append(image)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] load images BreaKHis dataset...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"OZHnpEJMzFRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513288219,"user_tz":-420,"elapsed":945,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"b28b0e9e-5e46-4374-f149-5120c7c0c201"},"source":["# normalization\n","print(\"[INFO] normalization...\")\n","test_x = np.array(images).astype(\"float32\") / 255.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] normalization...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"L3XY6-tvzFRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513292152,"user_tz":-420,"elapsed":4656,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"a3e34eda-4edd-4d11-98db-223587df1a29"},"source":["auto_encoder = ConvAutoEncoder.build(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)\n","# load our auto_encoder from disk\n","print(\"[INFO] loading auto encoder model...\")\n","auto_encoder.load_weights(\"training_1_40/cp.ckpt\")\n","with open('training_1_indexed_40.json') as f:\n","  training_indexed = json.load(f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\n","WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\n","WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n","[INFO] loading auto encoder model...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"6WMErJp7zFRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513295300,"user_tz":-420,"elapsed":7551,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"590f459d-3924-4aa6-fe9a-8a96be0bf427"},"source":["# create the encoder model which consists of *just* the encoder\n","# portion of the auto encoder\n","encoder = Model(inputs=auto_encoder.input,\n","\toutputs=auto_encoder.get_layer(\"encoded\").output)\n","\n","# quantify the contents of our input images using the encoder\n","print(\"[INFO] encoding images...\")\n","features_retrieved = encoder.predict(test_x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[INFO] encoding images...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"IBrghhIczFRD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513299298,"user_tz":-420,"elapsed":11363,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"89aa303e-1d74-4f5c-8bfd-57434f41a1f1"},"source":["query_indexes = list(range(0, test_x.shape[0]))\n","label_builder = list(np.unique(training_indexed[\"labels\"]))\n","class_builder = {label_unique:[] for label_unique in label_builder}\n","recalls = copy.deepcopy(class_builder)\n","precisions = copy.deepcopy(class_builder)\n","# loop over the testing indexes\n","for i in query_indexes:\n","    queryFeatures = features_retrieved[i]\n","    results = perform_search(queryFeatures, training_indexed, max_results=5)\n","    labels_ret = [training_indexed[\"labels\"][r[1]] for r in results]\n","    label_true = dataset[i].split(\"/\")[3]\n","    label_trues = [label_true for _ in labels_ret]\n","    recall = metric.recall_score(label_trues, labels_ret, average='weighted')\n","    precision = metric.precision_score(label_trues, labels_ret, average='weighted')\n","    recalls[label_true].append(recall)\n","    precisions[label_true].append(precision)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"pycharm":{"name":"#%%\n"},"id":"AxSCPcNEzFRE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611513299303,"user_tz":-420,"elapsed":11157,"user":{"displayName":"Kharisma Muzaki Ghufron","photoUrl":"","userId":"14730718725881384856"}},"outputId":"6ee8d7ee-83a3-4dd6-ccc8-488ed763a1b8"},"source":["print(\"recall values:\")\n","comb_recall, comb_precision = [], []\n","for key in recalls.keys():\n","    average_val = np.average(recalls[key])\n","    print(key, average_val)\n","    comb_recall.append(average_val)\n","print(\"combined recall\", np.average(comb_recall))\n","\n","print(\"\\nprecision values:\")\n","for key in precisions.keys():\n","    average_val = np.average(precisions[key])\n","    print(key, average_val)\n","    comb_precision.append(average_val)\n","print(\"combined precision\", np.average(comb_precision))\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["recall values:\n","benign 0.6903225806451615\n","malignant 0.8554744525547444\n","combined recall 0.7728985165999529\n","\n","precision values:\n","benign 0.9193548387096774\n","malignant 0.9854014598540146\n","combined precision 0.9523781492818459\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3dXyYHIQ-QhQ"},"source":[""],"execution_count":null,"outputs":[]}]}